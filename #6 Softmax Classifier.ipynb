{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 6.926112\n",
      "200 0.6005018\n",
      "400 0.4729582\n",
      "600 0.37342912\n",
      "800 0.2801835\n",
      "1000 0.23280513\n",
      "1200 0.21065336\n",
      "1400 0.192299\n",
      "1600 0.1768232\n",
      "1800 0.16359553\n",
      "2000 0.1521616\n",
      "--------------\n",
      "[[1.3890432e-03 9.9860197e-01 9.0612402e-06]] [1]\n",
      "--------------\n",
      "[[0.93119204 0.06290206 0.00590588]] [0]\n",
      "--------------\n",
      "[[1.2732767e-08 3.3411323e-04 9.9966586e-01]] [2]\n",
      "--------------\n",
      "[[1.3890432e-03 9.9860197e-01 9.0612402e-06]\n",
      " [9.3119204e-01 6.2902056e-02 5.9058843e-03]\n",
      " [1.2732767e-08 3.3411323e-04 9.9966586e-01]] [1 0 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n0 6.926112\\n200 0.6005015\\n400 0.47295815\\n600 0.37342924\\n800 0.28018373\\n1000 0.23280522\\n1200 0.21065344\\n1400 0.19229904\\n1600 0.17682323\\n1800 0.16359556\\n2000 0.15216158\\n-------------\\n[[1.3890490e-03 9.9860185e-01 9.0613084e-06]] [1]\\n-------------\\n[[0.9311919  0.06290216 0.00590591]] [0]\\n-------------\\n[[1.2732815e-08 3.3411323e-04 9.9966586e-01]] [2]\\n-------------\\n[[1.3890490e-03 9.9860185e-01 9.0613084e-06]\\n [9.3119192e-01 6.2902197e-02 5.9059085e-03]\\n [1.2732815e-08 3.3411323e-04 9.9966586e-01]] [1 0 2]\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lab 6 Softmax Classifier\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "x_data = [[1, 2, 1, 1],\n",
    "          [2, 1, 3, 2],\n",
    "          [3, 1, 3, 4],\n",
    "          [4, 1, 5, 5],\n",
    "          [1, 7, 5, 5],\n",
    "          [1, 2, 5, 6],\n",
    "          [1, 6, 6, 6],\n",
    "          [1, 7, 7, 7]]###4개의 x\n",
    "y_data = [[0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 0, 1],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [0, 1, 0],\n",
    "          [1, 0, 0],\n",
    "          [1, 0, 0]]###3개의 class 3개중하나를 선택해야함 이걸 선택하기 위해선 (one-hot-encoding) 정답인 자리만 1로 한다.\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 4])\n",
    "Y = tf.placeholder(\"float\", [None, 3])##shape 조심 class가 3개이기 때문에 \n",
    "nb_classes = 3 \n",
    "\n",
    "W = tf.Variable(tf.random_normal([4, nb_classes]), name='weight')#[4,np_clases] 들어오는 값 나가는 값\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "hypothesis = tf.nn.softmax(tf.matmul(X, W) + b)####softmax 구현 !! \n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis=1))###cross_entropy-error\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:#session을 열고 학습을 시키는 과정\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(2001):\n",
    "            _, cost_val = sess.run([optimizer, cost], feed_dict={X: x_data, Y: y_data})\n",
    "\n",
    "            if step % 200 == 0:\n",
    "                print(step, cost_val)\n",
    "\n",
    "    print('--------------')\n",
    "    # Testing & One-hot encoding\n",
    "    a = sess.run(hypothesis, feed_dict={X: [[1, 11, 7, 9]]})\n",
    "    print(a, sess.run(tf.argmax(a, 1)))\n",
    "\n",
    "    print('--------------')\n",
    "    b = sess.run(hypothesis, feed_dict={X: [[1, 3, 4, 3]]})\n",
    "    print(b, sess.run(tf.argmax(b, 1)))\n",
    "\n",
    "    print('--------------')\n",
    "    c = sess.run(hypothesis, feed_dict={X: [[1, 1, 0, 1]]})\n",
    "    print(c, sess.run(tf.argmax(c, 1)))\n",
    "\n",
    "    print('--------------')\n",
    "    all = sess.run(hypothesis, feed_dict={X: [[1, 11, 7, 9], [1, 3, 4, 3], [1, 1, 0, 1]]})\n",
    "    print(all, sess.run(tf.argmax(all, 1)))\n",
    "\n",
    "'''\n",
    "0 6.926112\n",
    "200 0.6005015\n",
    "400 0.47295815\n",
    "600 0.37342924\n",
    "800 0.28018373\n",
    "1000 0.23280522\n",
    "1200 0.21065344\n",
    "1400 0.19229904\n",
    "1600 0.17682323\n",
    "1800 0.16359556\n",
    "2000 0.15216158\n",
    "-------------\n",
    "[[1.3890490e-03 9.9860185e-01 9.0613084e-06]] [1]\n",
    "-------------\n",
    "[[0.9311919  0.06290216 0.00590591]] [0]\n",
    "-------------\n",
    "[[1.2732815e-08 3.3411323e-04 9.9966586e-01]] [2]\n",
    "-------------\n",
    "[[1.3890490e-03 9.9860185e-01 9.0613084e-06]\n",
    " [9.3119192e-01 6.2902197e-02 5.9059085e-03]\n",
    " [1.2732815e-08 3.3411323e-04 9.9966586e-01]] [1 0 2]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(101, 16) (101, 1)\n",
      "one_hot: Tensor(\"one_hot:0\", shape=(?, 1, 7), dtype=float32)\n",
      "reshape one_hot: Tensor(\"Reshape:0\", shape=(?, 7), dtype=float32)\n",
      "Step:     0\tCost: 4.144\tAcc: 25.74%\n",
      "Step:   100\tCost: 0.654\tAcc: 79.21%\n",
      "Step:   200\tCost: 0.418\tAcc: 87.13%\n",
      "Step:   300\tCost: 0.308\tAcc: 92.08%\n",
      "Step:   400\tCost: 0.245\tAcc: 95.05%\n",
      "Step:   500\tCost: 0.205\tAcc: 95.05%\n",
      "Step:   600\tCost: 0.176\tAcc: 97.03%\n",
      "Step:   700\tCost: 0.154\tAcc: 98.02%\n",
      "Step:   800\tCost: 0.137\tAcc: 98.02%\n",
      "Step:   900\tCost: 0.123\tAcc: 98.02%\n",
      "Step:  1000\tCost: 0.112\tAcc: 99.01%\n",
      "Step:  1100\tCost: 0.103\tAcc: 99.01%\n",
      "Step:  1200\tCost: 0.094\tAcc: 100.00%\n",
      "Step:  1300\tCost: 0.088\tAcc: 100.00%\n",
      "Step:  1400\tCost: 0.082\tAcc: 100.00%\n",
      "Step:  1500\tCost: 0.076\tAcc: 100.00%\n",
      "Step:  1600\tCost: 0.072\tAcc: 100.00%\n",
      "Step:  1700\tCost: 0.068\tAcc: 100.00%\n",
      "Step:  1800\tCost: 0.064\tAcc: 100.00%\n",
      "Step:  1900\tCost: 0.061\tAcc: 100.00%\n",
      "Step:  2000\tCost: 0.058\tAcc: 100.00%\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 4 True Y: 4\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 2 True Y: 2\n",
      "[True] Prediction: 3 True Y: 3\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 1 True Y: 1\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 5 True Y: 5\n",
      "[True] Prediction: 0 True Y: 0\n",
      "[True] Prediction: 6 True Y: 6\n",
      "[True] Prediction: 1 True Y: 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nStep:     0 Loss: 5.106 Acc: 37.62%\\nStep:   100 Loss: 0.800 Acc: 79.21%\\nStep:   200 Loss: 0.486 Acc: 88.12%\\n...\\nStep:  1800\\tLoss: 0.060\\tAcc: 100.00%\\nStep:  1900\\tLoss: 0.057\\tAcc: 100.00%\\nStep:  2000\\tLoss: 0.054\\tAcc: 100.00%\\n[True] Prediction: 0 True Y: 0\\n[True] Prediction: 0 True Y: 0\\n[True] Prediction: 3 True Y: 3\\n...\\n[True] Prediction: 0 True Y: 0\\n[True] Prediction: 6 True Y: 6\\n[True] Prediction: 1 True Y: 1\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lab 6 Softmax Classifier\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "tf.set_random_seed(777)  # for reproducibility\n",
    "\n",
    "# Predicting animal type based on various features\n",
    "xy = np.loadtxt('data-04-zoo.csv', delimiter=',', dtype=np.float32)\n",
    "x_data = xy[:, 0:-1]\n",
    "y_data = xy[:, [-1]]#데이터 읽어오기 \n",
    "\n",
    "print(x_data.shape, y_data.shape)\n",
    "\n",
    "'''\n",
    "(101, 16) (101, 1)\n",
    "'''\n",
    "\n",
    "nb_classes = 7  # 0 ~ 6\n",
    "\n",
    "X = tf.placeholder(tf.float32, [None, 16])#여기선 7개이기때문에 None은 7로 자동으로 될것!\n",
    "Y = tf.placeholder(tf.int32, [None, 1])  # 0 ~ 6\n",
    "\n",
    "Y_one_hot = tf.one_hot(Y, nb_classes)  # one hot\n",
    "print(\"one_hot:\", Y_one_hot)\n",
    "Y_one_hot = tf.reshape(Y_one_hot, [-1, nb_classes])#원핫은 reshape해야함!!!원핫을하게되면  한차원이 더 더해짐 !!! 그래서 차원하나를 빼야함\n",
    "#즉 원핫을 하게 되면 rank가 +1이됨 \n",
    "print(\"reshape one_hot:\", Y_one_hot)\n",
    "\n",
    "'''\n",
    "one_hot: Tensor(\"one_hot:0\", shape=(?, 1, 7), dtype=float32)\n",
    "reshape one_hot: Tensor(\"Reshape:0\", shape=(?, 7), dtype=float32)\n",
    "'''\n",
    "\n",
    "W = tf.Variable(tf.random_normal([16, nb_classes]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([nb_classes]), name='bias')\n",
    "\n",
    "# tf.nn.softmax computes softmax activations\n",
    "# softmax = exp(logits) / reduce_sum(exp(logits), dim)\n",
    "logits = tf.matmul(X, W) + b\n",
    "hypothesis = tf.nn.softmax(logits)\n",
    "\n",
    "# Cross entropy cost/loss\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,\n",
    "                                                                 labels=tf.stop_gradient([Y_one_hot])))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)\n",
    "\n",
    "prediction = tf.argmax(hypothesis, 1)##argmax는 one_hot_encoding에서 최고로 높은 값을 불러줌 ,1은 어떤축을 기준으로 할것인가.\n",
    "#예측한 값이 맞는지 틀린지 알고싶음@!!!\n",
    "correct_prediction = tf.equal(prediction, tf.argmax(Y_one_hot, 1))##예측한 것과 one-hot 정답 레이블과 비교 !\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))###맞게 예측한것들을 모아서 정확도를 구함\n",
    "\n",
    "# Launch graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for step in range(2001):\n",
    "        _, cost_val, acc_val = sess.run([optimizer, cost, accuracy], feed_dict={X: x_data, Y: y_data})\n",
    "                                        \n",
    "        if step % 100 == 0:\n",
    "            print(\"Step: {:5}\\tCost: {:.3f}\\tAcc: {:.2%}\".format(step, cost_val, acc_val))\n",
    "\n",
    "    # Let's see if we can predict\n",
    "    pred = sess.run(prediction, feed_dict={X: x_data})\n",
    "    # y_data: (N,1) = flatten => (N, ) matches pred.shape\n",
    "    for p, y in zip(pred, y_data.flatten()):#zip으로 묶음 각각의 엘리먼트를 [p,y]로 보내는것!!\n",
    "        print(\"[{}] Prediction: {} True Y: {}\".format(p == int(y), p, int(y)))\n",
    "\n",
    "'''\n",
    "Step:     0 Loss: 5.106 Acc: 37.62%\n",
    "Step:   100 Loss: 0.800 Acc: 79.21%\n",
    "Step:   200 Loss: 0.486 Acc: 88.12%#스탭을하면서 loss는 줄어들고 정확도는 계속 높아짐\n",
    "...\n",
    "Step:  1800\tLoss: 0.060\tAcc: 100.00%\n",
    "Step:  1900\tLoss: 0.057\tAcc: 100.00%\n",
    "Step:  2000\tLoss: 0.054\tAcc: 100.00%\n",
    "[True] Prediction: 0 True Y: 0\n",
    "[True] Prediction: 0 True Y: 0\n",
    "[True] Prediction: 3 True Y: 3\n",
    "...\n",
    "[True] Prediction: 0 True Y: 0\n",
    "[True] Prediction: 6 True Y: 6\n",
    "[True] Prediction: 1 True Y: 1\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
